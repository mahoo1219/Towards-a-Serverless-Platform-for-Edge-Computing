\section{Related Works}\label{sec:related_works}



Baresi et al.~\cite{GarrigaMendonca2017} was the first work to exploit a serverless architecture in the materialization of mobile edge computing (MEC). The present work aims to  deepen the discussion from the architectural and deployment perspectives. It also encompasses a broader range of application scenarios and types of fog infrastructures along with the optimization and additional services composing a \textit{Serverless Edge Platform}.

Aske et al.~\cite{Aske:2018} proposed a framework for supporting multi-provider serverless computing on the edge. Whilst the scheduling involving multiple 
%serverless edge 
providers is an interesting problem, in the present work we have focused on the materialization of a \textit{Serverless Edge Platform} from a single provider viewpoint. %In this sense, both works are complementary.

%TODO
Several works addressed the placement and migration of services in an N-tier fog-cloud topology~\cite{Wang:2015a,Plachy:2016,Machen:2018}. As proven elsewhere~\cite{Tarneberg:2017}, these problems are NP-Complex; the exiting solutions are based on heuristics and approximations.
The fundamental different concerning these works and the proposed architecture lies in the execution model: in contrast with \textit{always on} IaaS-based services, %(e.g., a VM-based web application), 
%functions are stateless, allocated on demand, and limited on their execution time. 
function migration is addressed with the creation of ephemeral CER instances by distinct SEPs, accordingly to the mobility of clients. Notwithstanding this, existing solutions are of particular interest for the placement problem discussed in Section~\ref{sec:SEP_EDA}.

More recently, a model for the management of FaaS composing a computing continuum of mobile, edge, and cloud resources was proposed by Baresi et al.~\cite{Baresi:2018}. Among others, the paper tackles the opportunistic allocation of functions onto mobile, edge, and cloud platforms based on the perceived latency and battery consumption. The resulting placement decision involves the participation of client devices. In contrast, the present work exploits the inter-platform cooperation within a single fog/cloud provider to render the placement of functions transparent to end-users. It also includes application scenarios others than mobile computation offloading. 

%Other works adopted the FaaS model in the definition of specific mechanisms governing the scheduling~\cite{Aske:2018} and life-cycle management~\cite{Baresi:2018} of edge-based functions. 

%The ENORM framework~\cite{Wang:2015a} --- for edge node resource --- shares some architectural characteristics.

